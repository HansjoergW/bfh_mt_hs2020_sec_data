{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core\n",
    "> API details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import findspark\n",
    "from pyspark.sql import SparkSession\n",
    "def get_spark_session(appname = \"default\"):\n",
    "    \"\"\"\n",
    "    Initialises a spark session. \n",
    "    Parameters:\n",
    "    appname - default is \"default\"\n",
    "    \"\"\"\n",
    "    findspark.init()\n",
    "    return SparkSession.builder \\\n",
    "                        .appName(appname) \\\n",
    "                        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File handling related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# code copied from https://www.thepythoncode.com/article/get-directory-size-in-bytes-using-python \n",
    "import os\n",
    "def get_directory_size(directory):\n",
    "    \"\"\"\n",
    "    Returns the `directory` size in bytes.\n",
    "    code copied from https://www.thepythoncode.com/article/get-directory-size-in-bytes-using-python \n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    try:\n",
    "        # print(\"[+] Getting the size of\", directory)\n",
    "        for entry in os.scandir(directory):\n",
    "            if entry.is_file():\n",
    "                # if it's a file, use stat() function\n",
    "                total += entry.stat().st_size\n",
    "            elif entry.is_dir():\n",
    "                # if it's a directory, recursively call this function\n",
    "                total += get_directory_size(entry.path)\n",
    "    except NotADirectoryError:\n",
    "        # if `directory` isn't a directory, get the file size then\n",
    "        return os.path.getsize(directory)\n",
    "    except PermissionError:\n",
    "        # if for whatever reason we can't open the folder, return 0\n",
    "        return 0\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# code copied from https://www.thepythoncode.com/article/get-directory-size-in-bytes-using-python \n",
    "def get_size_format(b, factor=1024, suffix=\"B\"):\n",
    "    \"\"\"\n",
    "    Scale bytes to its proper byte format\n",
    "    e.g:\n",
    "        1253656 => '1.20MB'\n",
    "        1253656678 => '1.17GB'\n",
    "    code copied from https://www.thepythoncode.com/article/get-directory-size-in-bytes-using-python \n",
    "    \"\"\"\n",
    "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\", \"E\", \"Z\"]:\n",
    "        if b < factor:\n",
    "            return f\"{b:.2f}{unit}{suffix}\"\n",
    "        b /= factor\n",
    "    return f\"{b:.2f}Y{suffix}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.30MB'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide\n",
    "get_size_format(get_directory_size(\".\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statement Processing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are different helper methods which make transformation of the data easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_data(folder, spark, stmt:str, attr:str):\n",
    "    \"\"\" Loads the pivoted data into a spark dataframe.\n",
    "    \"\"\"\n",
    "    return spark.read.parquet(folder + \"/\" + stmt + \"/\" + attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def spark_shape(self):\n",
    "    return (self.count(), len(self.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get count of both null and missing values in pyspark\n",
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "def get_empty_count(df):\n",
    "    return df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def complete_addition(df, sumcol, addcol1, addcol2):\n",
    "    \"\"\" \n",
    "    If there are columns that share the relation sumcol = addcol1 + addcol2\n",
    "    this function ensures that a missing value is calculated based on the other two   \n",
    "    \"\"\"\n",
    "    missingtwo = (df[sumcol].notnull()) & (df[addcol1].notnull()) & (df[addcol2].isnull())\n",
    "    df.loc[missingtwo, addcol2] = df.loc[missingtwo, sumcol] - df.loc[missingtwo, addcol1]\n",
    "\n",
    "    missingone = (df[sumcol].notnull()) & (df[addcol2].notnull()) & (df[addcol1].isnull())\n",
    "    df.loc[missingone, addcol1] = df.loc[missingone, sumcol] - df.loc[missingone, addcol2]  \n",
    "    \n",
    "    missingsum = (df[sumcol].isnull()) & (df[addcol2].notnull()) & (df[addcol1].notnull())\n",
    "    df.loc[missingsum, sumcol] = df.loc[missingsum, addcol1] + df.loc[missingsum, addcol2]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def copy_if_not_empty(df, sourcecol, targetcol, to_zero_col = None):\n",
    "    \"\"\" \n",
    "    copies the value from the sourceol to the targetcol if the sourcecol is not empty and the targetcol is empty.\n",
    "    As a third parameter, a column can be provided that has to be set to 0.0 in the rows where the values are copied    \n",
    "    \"\"\"\n",
    "    do_copy = (df[sourcecol].notnull()) & (df[targetcol].isnull())\n",
    "    df.loc[do_copy, targetcol] = df.loc[do_copy, sourcecol]\n",
    "    if to_zero_col != None:\n",
    "        df.loc[do_copy, to_zero_col] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sum_into_empty_target(df, add1col, add2col, targetcol):\n",
    "    \"\"\"\n",
    "    adds the value of two not empty columns and stores the result in the empty targetcol\n",
    "    \"\"\"\n",
    "    do_sum = (df[add1col].notnull()) & (df[add2col].notnull()) & (df[targetcol].isnull())\n",
    "    df.loc[do_sum, targetcol] = df.loc[do_sum, add1col] + df.loc[do_sum, add2col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def sum_cols_into_new_target(df, targetcol, sumcolslist):\n",
    "    \"\"\" sums up the value  of several columns and stores the result in the targetcol.\n",
    "        the columns that contain values to sum up may not be empty.\n",
    "    \"\"\"\n",
    "    df[targetcol] = 0.0\n",
    "    for col in sumcolslist:\n",
    "        set_to_zero_if_null(df, col)\n",
    "        df[targetcol] += df[col]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def copy_if_not_empty_for_ticker(df, ticker, sourcecol, targetcol, to_zero_col = None):\n",
    "    \"\"\" copy the not empty sourcecol to the empty targetcol of a certain ticker.\n",
    "        if provided, set the to_zero_col for the affected rows to zero.\n",
    "    \"\"\"\n",
    "    do_copy = (df['ticker'] == ticker) & (sel_df[sourcecol].notnull()) & (sel_df[targetcol].isnull())\n",
    "\n",
    "    df.loc[do_copy, targetcol] = df.loc[do_copy, sourcecol]\n",
    "    if to_zero_col != None:\n",
    "        df.loc[do_copy, to_zero_col] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def set_to_zero_if_null(df, col):\n",
    "    \"\"\" set null values of a column to 0.0\n",
    "    \"\"\"\n",
    "    do_set = (df[col].isnull())\n",
    "    df.loc[do_set, col] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def print_null_count(df, cols):\n",
    "    \"\"\" print out howmany null values the provided cols contain \n",
    "    \"\"\"\n",
    "    for col in cols:\n",
    "        print(col, ' ', df[col].isnull().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
