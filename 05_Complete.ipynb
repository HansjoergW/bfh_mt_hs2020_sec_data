{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# stellt sicher, dass beim verÃ¤ndern der core library diese wieder neu geladen wird\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from bfh_mt_hs2020_sec_data.core import * \n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Union, Set\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import shutil          # provides high level file operations\n",
    "import time            # used to measure execution time\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pivot_selected_folder  = \"D:/data/parq_pivot_select\"\n",
    "all_pivoted_folder = \"D:/data/parq_pivot_split\"\n",
    "all_processed_folder = \"D:/data/parq_processed/\"\n",
    "all_data_local_folder = \"./data/\"\n",
    "\n",
    "pivot_group = [\"cik\",\"ticker\",\"adsh\",\"period\",\"filed\",\"form\",\"qtrs\",\"fp\"]\n",
    "analyze_fields = [\"value_count\",\"null_count\",\"difference\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00_Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_null(df: pd.DataFrame):\n",
    "    columns = list(df.columns)\n",
    "    value_cols = set(columns) -  set(pivot_group)\n",
    "    value_cols = value_cols -  set(analyze_fields)\n",
    "    \n",
    "    df['value_count'] = df[value_cols].notnull().sum(axis=1)\n",
    "    df['null_count'] = df[value_cols].isnull().sum(axis=1)\n",
    "    \n",
    "    print(\"lines with missing values: \", df[df.null_count > 0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(stmt:str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(all_processed_folder + stmt + \"_not_cleaned.csv\")\n",
    "    df.period = pd.to_datetime(df.period)\n",
    "    df.filed = pd.to_datetime(df.filed)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_number_of_reports(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    check if there is only one entry per report (unique adsh)\n",
    "    \"\"\"\n",
    "    print(\"is there just one report per ADSH: \", len(df.adsh.unique()) == df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_value_report(df: pd.DataFrame):\n",
    "    df_missing = df[df.null_count > 0]\n",
    "    print(df_missing.shape[0])\n",
    "    sns.catplot(x='null_count', kind='count', data=df_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01_Complete BS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines with missing values:  1301\n"
     ]
    }
   ],
   "source": [
    "bs_df = load_data(\"bs\")\n",
    "count_null(bs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116519, 18)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is there just one report per ADSH:  True\n"
     ]
    }
   ],
   "source": [
    "check_number_of_reports(bs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### complete missing Equity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# complete Equity_hj = Assets - Liabilities\n",
    "do_set_equity = (bs_df.Equity_hj.isnull()  & bs_df.Assets.notnull() & bs_df.Liabilities.notnull())\n",
    "bs_df.loc[do_set_equity, 'Equity_hj'] = bs_df.loc[do_set_equity, 'Assets'] - bs_df.loc[do_set_equity, 'Liabilities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines with missing values:  559\n"
     ]
    }
   ],
   "source": [
    "count_null(bs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### complete missing liabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_set_liab = (bs_df.Assets.notnull()  & bs_df.Equity_hj.notnull()  & bs_df.Liabilities.isnull() & bs_df.LiabilitiesCurrent.isnull() & bs_df.LiabilitiesNoncurrent.isnull())\n",
    "bs_df.loc[do_set_liab, 'Liabilities'] = bs_df.loc[do_set_liab, 'Assets'] - bs_df.loc[do_set_liab, 'Equity_hj']\n",
    "bs_df.loc[do_set_liab, 'LiabilitiesCurrent'] = bs_df.loc[do_set_liab, 'Liabilities']\n",
    "bs_df.loc[do_set_liab, 'LiabilitiesNoncurrent'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines with missing values:  282\n"
     ]
    }
   ],
   "source": [
    "count_null(bs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### complete missing assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_set_liab = (bs_df.Liabilities.notnull()  & bs_df.Equity_hj.notnull()  & bs_df.Assets.isnull() & bs_df.AssetsCurrent.isnull() & bs_df.AssetsNoncurrent.isnull())\n",
    "bs_df.loc[do_set_liab, 'Assets'] = bs_df.loc[do_set_liab, 'Liabilities'] + bs_df.loc[do_set_liab, 'Equity_hj']\n",
    "bs_df.loc[do_set_liab, 'AssetsCurrent'] = bs_df.loc[do_set_liab, 'Liabilities']\n",
    "bs_df.loc[do_set_liab, 'AssetsNoncurrent'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines with missing values:  274\n"
     ]
    }
   ],
   "source": [
    "count_null(bs_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_to_drop = set(analyze_fields).intersection(set(bs_df.columns))\n",
    "bs_df.drop(columns=fields_to_drop).to_csv(all_data_local_folder + \"05_bs_completed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove companies with incomplete balancesheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    }
   ],
   "source": [
    "incomplete_ciks = bs_df[bs_df.null_count > 3].cik.unique()\n",
    "print(len(incomplete_ciks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_cleaned = bs_df[~bs_df.cik.isin(incomplete_ciks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114481, 18)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save them\n",
    "fields_to_drop = set(analyze_fields).intersection(set(bs_df.columns))\n",
    "bs_cleaned.drop(columns=fields_to_drop).to_csv(all_processed_folder + \"bs_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02_Complete CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines with missing values:  1359\n"
     ]
    }
   ],
   "source": [
    "cf_df = load_data(\"cf\")\n",
    "count_null(cf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116187, 18)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is there just one report per ADSH:  True\n"
     ]
    }
   ],
   "source": [
    "check_number_of_reports(cf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### complete CashIncreaseDecrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per definition CashIncreaseDecrease = NetCashProvidedByUsedInOperatingActivities + NetCashProvidedByUsedInInvestingActivities + NetCashProvidedByUsedInFinancingActivities\n",
    "do_set_cshinc = (cf_df.CashIncreaseDecrease_hj.isnull()  & cf_df.NetCashProvidedByUsedInOperatingActivities.notnull()  & \n",
    "                 cf_df.NetCashProvidedByUsedInInvestingActivities.notnull() & cf_df.NetCashProvidedByUsedInFinancingActivities.notnull())\n",
    "cf_df.loc[do_set_cshinc, 'CashIncreaseDecrease_hj'] = cf_df.loc[do_set_cshinc, 'NetCashProvidedByUsedInOperatingActivities'] \\\n",
    "                                                    + cf_df.loc[do_set_cshinc, 'NetCashProvidedByUsedInInvestingActivities'] \\\n",
    "                                                    + cf_df.loc[do_set_cshinc, 'NetCashProvidedByUsedInFinancingActivities'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines with missing values:  377\n"
     ]
    }
   ],
   "source": [
    "count_null(cf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### complete NetCashProvidedByUsedInOperatingActivities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per definition CashIncreaseDecrease = NetCashProvidedByUsedInOperatingActivities + NetCashProvidedByUsedInInvestingActivities + NetCashProvidedByUsedInFinancingActivities\n",
    "# hence NetCashProvidedByUsedInOperatingActivities = CashIncreaseDecrease - (NetCashProvidedByUsedInInvestingActivities + NetCashProvidedByUsedInFinancingActivities)\n",
    "do_set_netop = (cf_df.CashIncreaseDecrease_hj.notnull()  & cf_df.NetCashProvidedByUsedInOperatingActivities.isnull()  & \n",
    "                 cf_df.NetCashProvidedByUsedInInvestingActivities.notnull() & cf_df.NetCashProvidedByUsedInFinancingActivities.notnull())\n",
    "cf_df.loc[do_set_netop, 'NetCashProvidedByUsedInOperatingActivities'] = cf_df.loc[do_set_netop, 'CashIncreaseDecrease_hj'] \\\n",
    "                                                                      - (cf_df.loc[do_set_netop, 'NetCashProvidedByUsedInInvestingActivities']  + cf_df.loc[do_set_netop, 'NetCashProvidedByUsedInFinancingActivities'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines with missing values:  316\n"
     ]
    }
   ],
   "source": [
    "count_null(cf_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_to_drop = set(analyze_fields).intersection(set(cf_df.columns))\n",
    "cf_df.drop(columns=fields_to_drop).to_csv(all_data_local_folder + \"05_cf_completed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove companies with incomplete cash flow statment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n"
     ]
    }
   ],
   "source": [
    "incomplete_ciks = cf_df[cf_df.null_count > 1].cik.unique()\n",
    "print(len(incomplete_ciks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_cleaned = cf_df[~cf_df.cik.isin(incomplete_ciks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112417, 18)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_to_drop = set(analyze_fields).intersection(set(cf_df.columns))\n",
    "cf_cleaned.drop(columns=fields_to_drop).to_csv(all_processed_folder + \"cf_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03_Complete IS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines with missing values:  115883\n"
     ]
    }
   ],
   "source": [
    "is_df = load_data(\"is\")\n",
    "count_null(is_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115899, 21)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is there just one report per ADSH:  True\n"
     ]
    }
   ],
   "source": [
    "check_number_of_reports(is_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### complete GrossProfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per definition Grossprofit = Revenues - CostOfRevenue\n",
    "do_set_grossp = (is_df.Revenues_hj.notnull()  & is_df.CostOfRevenue_hj.notnull()  & is_df.GrossProfit.isnull())\n",
    "is_df.loc[do_set_grossp, 'GrossProfit'] = is_df.loc[do_set_grossp, 'Revenues_hj'] - is_df.loc[do_set_grossp, 'CostOfRevenue_hj']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per definition: grossprofit - opexpenses = op-income -> grossprofit = opincome + opexpenses\n",
    "do_set_grossp1 = (is_df.OperatingExpenses.notnull()  & is_df.OperatingIncomeLoss_hj.notnull()  & is_df.GrossProfit.isnull())\n",
    "is_df.loc[do_set_grossp1, 'GrossProfit'] = is_df.loc[do_set_grossp1, 'OperatingIncomeLoss_hj'] + is_df.loc[do_set_grossp1, 'OperatingExpenses']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### complete Revenues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per definition Grossprofit = Revenues - CostOfRevenue -> Revenues = Grossprofit + CostOfRevenue\n",
    "do_set_rev = (is_df.Revenues_hj.isnull()  & is_df.CostOfRevenue_hj.notnull()  & is_df.GrossProfit.notnull())\n",
    "is_df.loc[do_set_rev, 'Revenues_hj'] = is_df.loc[do_set_rev, 'CostOfRevenue_hj'] - is_df.loc[do_set_rev, 'GrossProfit']\n",
    "set_to_zero_if_null(is_df,'Revenues_hj')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### complete CostOfRevenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per definition Grossprofit = Revenues - CostOfRevenue -> CostOfRevenue = Revenues - Grossprofit\n",
    "do_set_cstrev = (is_df.Revenues_hj.notnull()  & is_df.CostOfRevenue_hj.isnull()  & is_df.GrossProfit.notnull())\n",
    "is_df.loc[do_set_cstrev, 'CostOfRevenue_hj'] = is_df.loc[do_set_cstrev, 'Revenues_hj'] - is_df.loc[do_set_cstrev, 'GrossProfit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### complete OperatingIncomeLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# per definition: opIncomeLoss = grossprofit - opexpenses\n",
    "do_set_opinc = (is_df.OperatingExpenses.notnull()  & is_df.GrossProfit.notnull()  & is_df.OperatingIncomeLoss_hj.isnull())\n",
    "is_df.loc[do_set_opinc, 'OperatingIncomeLoss_hj'] = is_df.loc[do_set_opinc, 'GrossProfit'] - is_df.loc[do_set_opinc, 'OperatingExpenses']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3903"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(is_df.OperatingIncomeLoss_hj.isnull()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimate OperatingIncomeLoss_hj based on GrossProfit and NetIncomeLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if OperatingIncomeLoss is not set, we can try to estimate it based on the average compared to GrossProfit and NetIncomeLoss\n",
    "\n",
    "# based on existing OperatingIncomeLoss_hj Values, we calculate the average OperatingIncomeLoss_hj between GrossProfit and NetIncomeLoss (in percent)\n",
    "#  we may only consider entries where NetIncomeLoss isn't equal to GrossProfit. since this would cause a division by zero\n",
    "calc_mean_opinc_avg = (is_df.GrossProfit.notnull()  & is_df.NetIncomeLoss_hj.notnull()  & is_df.OperatingIncomeLoss_hj.notnull() & (is_df.NetIncomeLoss_hj != is_df.GrossProfit))\n",
    "selected_cols = is_df[calc_mean_opinc_avg][['NetIncomeLoss_hj','GrossProfit','OperatingIncomeLoss_hj']].copy()\n",
    "\n",
    "avg_opinc = ((selected_cols.GrossProfit-selected_cols.OperatingIncomeLoss_hj)/(selected_cols.GrossProfit-selected_cols.NetIncomeLoss_hj)).mean()\n",
    "\n",
    "# if we have grossprofit and NetIncomeLoss_hj, we try estimate OperatingIncomeLoss based on the average position\n",
    "do_updated_opinc = (is_df.GrossProfit.notnull() & is_df.OperatingIncomeLoss_hj.isnull() & is_df.NetIncomeLoss_hj.notnull())\n",
    "\n",
    "is_df.loc[do_updated_opinc,'OperatingIncomeLoss_hj'] = is_df.loc[do_updated_opinc,'GrossProfit'] \\\n",
    "                                    - avg_opinc * (is_df.loc[do_updated_opinc,'GrossProfit'] - is_df.loc[do_updated_opinc,'NetIncomeLoss_hj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3597"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(is_df.OperatingIncomeLoss_hj.isnull()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimate OperatingIncomeLoss_hj based on Revenues and NetIncomeLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if OperatingIncomeLoss is not set, we can try to estimate it based on the average compared to Revenues and NetIncomeLoss\n",
    "\n",
    "# based on existing OperatingIncomeLoss_hj Values, we calculate the average OperatingIncomeLoss_hj between Revenue and NetIncomeLoss (in percent)\n",
    "calc_mean_opinc_avg = ((is_df.Revenues_hj > 0.0)  & (is_df.NetIncomeLoss_hj.notnull()  & is_df.OperatingIncomeLoss_hj.notnull()))\n",
    "selected_cols = is_df[calc_mean_opinc_avg][['NetIncomeLoss_hj','Revenues_hj','OperatingIncomeLoss_hj']].copy()\n",
    "\n",
    "avg_opinc = ((selected_cols.Revenues_hj-selected_cols.OperatingIncomeLoss_hj)/(selected_cols.Revenues_hj-selected_cols.NetIncomeLoss_hj)).mean()\n",
    "\n",
    "# if we have revenue and NetIncomeLoss_hj, we try estimate OperatingIncomeLoss based on the average position\n",
    "do_updated_opinc = (is_df.Revenues_hj.notnull() & is_df.OperatingIncomeLoss_hj.isnull() & is_df.NetIncomeLoss_hj.notnull())\n",
    "\n",
    "is_df.loc[do_updated_opinc,'OperatingIncomeLoss_hj'] = is_df.loc[do_updated_opinc,'Revenues_hj'] \\\n",
    "                                    - avg_opinc * (is_df.loc[do_updated_opinc,'Revenues_hj'] - is_df.loc[do_updated_opinc,'NetIncomeLoss_hj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(is_df.OperatingIncomeLoss_hj.isnull()).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### estimate GrossProfit based on Revenue and OperatingIncomeLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if Grossprofit is not set, we can try to estimate it based on the average compared to reveneue and operatingIncomeLoss\n",
    "\n",
    "# based on existing GrossProfit Values, we calculate the average grossprofit between Revenue and OperatingIncome (in percent)\n",
    "calc_mean_gp_selection = ((is_df.Revenues_hj > 0.0)  & (is_df.GrossProfit.notnull()  & is_df.OperatingIncomeLoss_hj.notnull()))\n",
    "selected_cols = is_df[calc_mean_gp_selection][['Revenues_hj','GrossProfit','OperatingIncomeLoss_hj']].copy()\n",
    "\n",
    "avg_gross = ((selected_cols.Revenues_hj-selected_cols.GrossProfit)/(selected_cols.Revenues_hj-selected_cols.OperatingIncomeLoss_hj)).mean()\n",
    "\n",
    "# if we have revenue and operatingincome, we try estimate grossprofit based on the average position\n",
    "do_updated_grossprofit = (is_df.Revenues_hj.notnull() & is_df.OperatingIncomeLoss_hj.notnull() & is_df.GrossProfit.isnull())\n",
    "\n",
    "is_df.loc[do_updated_grossprofit,'GrossProfit'] = is_df.loc[do_updated_grossprofit,'Revenues_hj'] \\\n",
    "                                    - avg_gross * (is_df.loc[do_updated_grossprofit,'Revenues_hj'] - is_df.loc[do_updated_grossprofit,'OperatingIncomeLoss_hj'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "621"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(is_df.Revenues_hj.isnull() | is_df.GrossProfit.isnull() | is_df.OperatingIncomeLoss_hj.isnull() | is_df.NetIncomeLoss_hj.isnull()).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = list(pivot_group)\n",
    "fields.extend(['Revenues_hj','GrossProfit','OperatingIncomeLoss_hj','NetIncomeLoss_hj', 'SharesOutstanding_hj','EarningsPerShare_hj'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_df[fields].to_csv(all_data_local_folder + \"05_is_completed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove companies with incomplete income statment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n"
     ]
    }
   ],
   "source": [
    "incomplete_ciks = is_df[(is_df.Revenues_hj.isnull() | is_df.GrossProfit.isnull() | is_df.OperatingIncomeLoss_hj.isnull() | is_df.NetIncomeLoss_hj.isnull())].cik.unique()\n",
    "print(len(incomplete_ciks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cleaned = is_df[~is_df.cik.isin(incomplete_ciks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111495, 21)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cleaned[fields].to_csv(all_processed_folder + \"is_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XX_Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_df[((is_df.Revenues_hj.notnull() & is_df.GrossProfit.notnull() & is_df.OperatingIncomeLoss_hj.isnull() & is_df.NetIncomeLoss_hj.notnull() ))] \\\n",
    "  [['cik','adsh','Revenues_hj','GrossProfit','OperatingIncomeLoss_hj', 'NetIncomeLoss_hj', 'OperatingExpenses','CostsAndExpenses']] #721"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_df[((is_df.Revenues_hj.isnull() | is_df.GrossProfit.isnull() | is_df.OperatingIncomeLoss_hj.isnull() | is_df.NetIncomeLoss_hj.isnull() ))] \\\n",
    "  [['cik','adsh','Revenues_hj','GrossProfit','OperatingIncomeLoss_hj', 'NetIncomeLoss_hj', 'OperatingExpenses','CostsAndExpenses']] #721"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_df[((is_df.CostsAndExpenses.notnull() & is_df.GrossProfit.isnull() & is_df.OperatingIncomeLoss_hj.isnull()))][['cik','adsh','CostsAndExpenses', 'OperatingExpenses','GrossProfit','OperatingIncomeLoss_hj']] #721\n",
    "#is_df[((is_df.OperatingExpenses.notnull() & is_df.GrossProfit.isnull() & is_df.OperatingIncomeLoss_hj.notnull()))][['cik','adsh','OperatingExpenses','GrossProfit','OperatingIncomeLoss_hj']] #11618"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_df.adsh.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value_report(cf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bs_df.adsh.unique()) == bs_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1349"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bs_df.qtrs>0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "IS\n",
    "Was kann man alles berechnen, wenn vorhanden\n",
    "GrossProfit = Revenues - costofsales\n",
    "OperatingIncome = (GrossProfit) - CostsAndExpenses\n",
    "OperatingIncome = Revenues - CostsAndExpenses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cf_df[(cf_df.null_count == 4)]\n",
    "print(df.shape[0])\n",
    "print(df.ticker.value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
