{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp prepare_whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "# stellt sicher, dass beim ver√§ndern der core library diese wieder neu geladen wird\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from bfh_mt_hs2020_sec_data.core import get_spark_session # initialze spark\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Union, Set\n",
    "import urllib.request  # used to download resources from the web \n",
    "import shutil          # provides high level file operations\n",
    "import time            # used to measure execution time\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.dataframe import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Definitions\n",
    "all_zip_folder = \"d:/data/sec_zips/\"\n",
    "target_csv_folder = \"d:/data/zip_joined/\"\n",
    "extract_temp_folder = \"d:/data/tmp/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(all_zip_folder).mkdir(parents=True, exist_ok=True)\n",
    "Path(target_csv_folder).mkdir(parents=True, exist_ok=True)\n",
    "Path(extract_temp_folder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.163:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>default</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1aadf179188>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init Spark\n",
    "spark = get_spark_session() # Session anlegen\n",
    "spark # display the moste important information of the session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01_Download_ZIP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare download urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definitions to create download urls\n",
    "sec_base_path = \"https://www.sec.gov/files/dera/data/financial-statement-data-sets/\"\n",
    "start_year = 2009        # start year to download the data\n",
    "end_year   = 2020        # end year for download\n",
    "format_str = \"{}q{}.zip\" # all file names are like 2020q1.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list with all download links\n",
    "download_urls = []\n",
    "for year in range(start_year, end_year + 1):\n",
    "    for quarter in range(1,5):\n",
    "        download_urls.append(sec_base_path + format_str.format(year, quarter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_urls.append(\"https://www.sec.gov/files/node/add/data_distribution/2020q1.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_urls_df = spark.createDataFrame(download_urls, StringType())\n",
    "download_urls_df = download_urls_df.withColumnRenamed(\"value\",\"url\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloader_function(url):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "  \n",
    "    # From URL construct the destination path and filename.\n",
    "    file_name = os.path.basename(urllib.parse.urlparse(url).path)\n",
    "    file_path = os.path.join(all_zip_folder, file_name) \n",
    "\n",
    "    # Check if the file has already been downloaded.\n",
    "    if os.path.exists(file_path):\n",
    "        return \"already downloaded\"\n",
    "\n",
    "    # Download and write to file.\n",
    "    try:\n",
    "        with urllib.request.urlopen(url, timeout=30) as urldata,\\\n",
    "              open(file_path, 'wb') as out_file:\n",
    "            shutil.copyfileobj(urldata, out_file)\n",
    "            return \"success\"\n",
    "    except Exception as ex:\n",
    "        return \"failed: {}\".format(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloader_udf = udf(lambda s: downloader_function(s), StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution time:       14.016472101211548\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "result_df =  download_urls_df.select('url', downloader_udf('url').alias('result')).collect()\n",
    "execution_time = (time.time() - start_time)\n",
    "print(\"execution time:      \", execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2009q1.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2009q2.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2009q3.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2009q4.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2010q1.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2010q2.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2010q3.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2010q4.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2011q1.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2011q2.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2011q3.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2011q4.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2012q1.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2012q2.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2012q3.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2012q4.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2013q1.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2013q2.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2013q3.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2013q4.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2014q1.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2014q2.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2014q3.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2014q4.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2015q1.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2015q2.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2015q3.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2015q4.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2016q1.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2016q2.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2016q3.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2016q4.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2017q1.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2017q2.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2017q3.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2017q4.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2018q1.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2018q2.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2018q3.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2018q4.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2019q1.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2019q2.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2019q3.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2019q4.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2020q1.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2020q2.zip', result='already downloaded'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2020q3.zip', result='failed: HTTP Error 404: Not Found'),\n",
       " Row(url='https://www.sec.gov/files/dera/data/financial-statement-data-sets/2020q4.zip', result='failed: HTTP Error 404: Not Found'),\n",
       " Row(url='https://www.sec.gov/files/node/add/data_distribution/2020q1.zip', result='already downloaded')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## join sec data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants for the names of the filese inside the zip file\n",
    "SUB_TXT = \"sub.txt\"\n",
    "PRE_TXT = \"pre.txt\"\n",
    "NUM_TXT = \"num.txt\"\n",
    "TAG_TXT = \"tag.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list with paths to all the zip files\n",
    "all_zip_path = Path(all_zip_folder)\n",
    "zip_files = [str(file) for file in all_zip_path.glob(\"*.zip\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_in_zip_into_df_extract(zip_file: str, data_file: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "       Extracts the data from zipfile and stores it on disk. \n",
    "       Uses spark.csv.read to read the data into the df\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(zip_file, \"r\") as container_zip:\n",
    "        with container_zip.open(data_file) as f:\n",
    "            # create a unique tempfile to extract the data\n",
    "            tempfile = extract_temp_folder +Path(zip_file).name.replace(\".zip\",\"\").replace(\"/\",\"\").replace(\"\\\\\",\"\")+\"_\"+data_file\n",
    "            \n",
    "            with open(tempfile, \"wb+\") as f_temp:\n",
    "                data = f.read()\n",
    "                f_temp.write(data)\n",
    "                f_temp.close()\n",
    "                f_temp_dbfs  = tempfile.replace(\"/dbfs\",\"\")\n",
    "         \n",
    "                df = spark.read.csv(f_temp_dbfs, sep='\\t', header=True)\n",
    "                return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_files(zip_file: str, target_folder: str) -> str:\n",
    "    \"\"\"\n",
    "        Joins the content of the 3 csv files that are contained in the provided zip_file and \n",
    "        create on csv file containing all relevant columns inside target_folder.\n",
    "    \"\"\"\n",
    "    \n",
    "    target_path = target_folder + Path(zip_file).name.replace(\".zip\",\"\").replace(\"/\",\"\").replace(\"\\\\\",\"\")\n",
    "    \n",
    "    if os.path.exists(target_path):\n",
    "        return zip_file + \" : \" + \" already Joined\"\n",
    "    \n",
    "    df_sub = read_csv_in_zip_into_df_extract(zip_file, SUB_TXT)\n",
    "    df_pre = read_csv_in_zip_into_df_extract(zip_file, PRE_TXT)\n",
    "    df_num = read_csv_in_zip_into_df_extract(zip_file, NUM_TXT)\n",
    "    \n",
    "    df_joined = df_num.join(df_sub, [\"adsh\"]).join(df_pre, [\"adsh\",\"tag\",\"version\"],\"left\")\n",
    "    \n",
    "    target_path  = target_path.replace(\"/dbfs\",\"\")\n",
    "    df_joined.write.csv(target_path, compression=\"gzip\", header=True)\n",
    "    \n",
    "    return target_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\data\\sec_zips\\2009q1.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2009q2.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2009q3.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2009q4.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2010q1.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2010q2.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2010q3.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2010q4.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2011q1.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2011q2.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2011q3.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2011q4.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2012q1.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2012q2.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2012q3.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2012q4.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2013q1.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2013q2.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2013q3.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2013q4.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2014q1.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2014q2.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2014q3.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2014q4.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2015q1.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2015q2.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2015q3.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2015q4.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2016q1.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2016q2.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2016q3.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2016q4.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2017q1.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2017q2.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2017q3.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2017q4.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2018q1.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2018q2.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2018q3.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2018q4.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2019q1.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2019q2.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2019q3.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2019q4.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2020q1.zip :  already Joined\n",
      "d:\\data\\sec_zips\\2020q2.zip :  already Joined\n"
     ]
    }
   ],
   "source": [
    "for file in zip_files:\n",
    "    try: \n",
    "        print(join_files(file, target_csv_folder))\n",
    "    except Exception as ex:\n",
    "        print(\"failed: \", file, str(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Code to clear the extract_temp_folder\n",
    "shutil.rmtree(extract_temp_folder)\n",
    "Path(extract_temp_folder).mkdir(parents=True, exist_ok=True) # create directory after it was deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
